
# GPT From Scratch

I truly enjoy building things from scratch. I feel it gives me a more nuanced understanding of the underlying concepts. In this repo, I am continuing my explorations by building a GPT from scratch.

In particular, I have built a character level, decoder only GPT which I have trained on the "Tiny Shakespeare" dataset. Further, I am recreating the implementation of the GPT tokenizer, following along with Andrej Karpathy's tutorials. Lastly, I will try to implement the GPT-2 model as well from scratch here.

## Acknowledgements

I have relied heavily on Andrej Karpathy's YouTube playlist of NN Zero to Hero, and along with it, Mitesh Khapra Sir's lectures on Deep Learning and Large Language Models. You can find the links to those resources here:

- [NN Zero to Hero](https://youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&feature=shared)
- [Mitesh Sir's Lectures](https://youtube.com/playlist?list=PLZ2ps__7DhBbaMNZoyW2Hizl8DG6ikkjo&feature=shared)
