{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Datasets\n",
    "\n",
    "Tiny Shakespeare dataset was really small. With 0.5 million tokens in a batch size, we will be processing the entire dataset in two epochs. So we need bigger dataset, especially when training on multiple GPUs."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
